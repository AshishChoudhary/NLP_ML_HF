{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Keyword Extraction with Hugging Face Transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at sentence-transformers/distilbert-base-nli-mean-tokens and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Word  hugging face is creating\n",
                        " Word  a tool\n",
                        " Word  that democratizes\n",
                        " Word  ai by\n",
                        " Word  giving the\n",
                        " Word  community the best\n",
                        " Word  tools for natural language processing.\n"
                    ]
                }
            ],
            "source": [
                "from transformers import pipeline\n",
                "import pandas as pd\n",
                "\n",
                "# Initialize the Named Entity Recognition (NER) pipeline with a specific model\n",
                "model_name = \"sentence-transformers/distilbert-base-nli-mean-tokens\"\n",
                "extractor = pipeline(\"ner\", model=model_name, aggregation_strategy=\"simple\",)\n",
                "\n",
                "# Example text for extraction\n",
                "text = \"Hugging Face is creating a tool that democratizes AI by giving the community the best tools for natural language processing.\"\n",
                "\n",
                "ngram_range_i = (1, 2)  # Extract both unigrams and bigrams\n",
                "\n",
                "# Extract named entities (which can be considered as keywords)\n",
                "entities = extractor(text)\n",
                "\n",
                "# Optional: Convert entities to a DataFrame for better visualization\n",
                "df = pd.DataFrame(entities)\n",
                "#print(df.head())\n",
                "#print(df.describe())\n",
                "#print(df[\"word\"])\n",
                "for v in df['word']:\n",
                "    print(' Word ',v)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracted Keywords:\n",
                        "hugging face\n",
                        "democratizes ai\n",
                        "face creating\n",
                        "ai giving\n",
                        "natural language\n",
                        "best tools\n",
                        "natural\n",
                        "processing\n",
                        "giving community\n",
                        "best\n"
                    ]
                }
            ],
            "source": [
                "from keybert import KeyBERT\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "\n",
                "# Initialize the KeyBERT model\n",
                "kw_model = KeyBERT()\n",
                "\n",
                "# Example text for extraction\n",
                "#text = \"Artificial Intelligence is revolutionizing the tech industry by enabling machines to learn from data and make decisions with minimal human intervention.\"\n",
                "text = \"Hugging Face is creating a tool that democratizes AI by giving the community the best tools for natural language processing.\"\n",
                "\n",
                "# Define n-gram range\n",
                "ngram_range = (1, 2)  # Extract both unigrams and bigrams\n",
                "\n",
                "# Extract keywords with MMR\n",
                "keywords = kw_model.extract_keywords(\n",
                "    text,\n",
                "    keyphrase_ngram_range=ngram_range,\n",
                "    use_mmr=True,\n",
                "    diversity=0.5,  # MMR diversity parameter\n",
                "    stop_words='english',\n",
                "    top_n=10,\n",
                ")\n",
                "\n",
                "# Print the extracted keywords\n",
                "print(\"Extracted Keywords:\")\n",
                "for keyword in keywords:\n",
                "    print(keyword[0])\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
