{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Summary:\n",
      "MsgUser: Hi, I need help with deploying a model using Streamlit.MsgAssistant: Sure! What specific issues are you facing? _______________________________________________==========================================================User: I'm getting an error when I try to import the 'pipeline' from transformers. I'm not sure what's wrong with that. _______________________________________________________============Assistant: That might be due to an incorrect installation or version mismatch. Can you share the exact error message?\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-base\")\n",
    "\n",
    "# Example chat history with formatting\n",
    "chat_history = \"\"\"\n",
    "User: Hi, I need help with deploying a model using Streamlit.\n",
    "Assistant: Sure! What specific issues are you facing?\n",
    "User: I'm getting an error when I try to import the 'pipeline' from transformers.\n",
    "Assistant: That might be due to an incorrect installation or version mismatch. Can you share the exact error message?\n",
    "User: The error says, 'ImportError: cannot import name 'pipeline' from 'transformers'.\n",
    "Assistant: It seems like there might be an issue with the installed version of the transformers library. \n",
    "Try updating it to the latest version using 'pip install --upgrade transformers'.\n",
    "User: I tried that, but now I'm getting an error related to TensorFlow when running the app.\n",
    "Assistant: You might need to ensure that TensorFlow is properly installed and compatible with the hardware. \n",
    "You can also try running the app with a smaller model if you're facing resource constraints.\n",
    "User: Thanks! That worked, but now the app is slow. Can you suggest a smaller model?\n",
    "Assistant: You can use 'facebook/bart-base' instead of 'bart-large-cnn' for summarization. It's smaller and faster.\n",
    "User: Great! That fixed it. Thanks for your help!\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the chat history\n",
    "summary = summarizer(chat_history, max_length=100, min_length=50, do_sample=False)\n",
    "\n",
    "# Print the summarized chat\n",
    "print(\"Chat Summary:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "user: I'm getting an error when I try to import the 'pipeline' from transformers . that might be due to an incorrect installation or version mismatch .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the summarization pipeline with the T5-base model\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\")\n",
    "\n",
    "# Example text for summarization\n",
    "# text = \"\"\"\n",
    "# Artificial intelligence (AI) is rapidly transforming the way we live and work. \n",
    "# From healthcare to finance, AI is enabling new ways of doing things that were previously thought impossible. \n",
    "# One of the key areas where AI is making a significant impact is in natural language processing (NLP), \n",
    "# where it is helping computers understand and generate human language in ways that are more accurate and efficient than ever before. \n",
    "# As AI technology continues to evolve, it is expected to play an even greater role in our daily lives, \n",
    "# leading to new opportunities and challenges across a wide range of industries.\n",
    "# \"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "User: Hi, I need help with deploying a model using Streamlit.\n",
    "Assistant: Sure! What specific issues are you facing?\n",
    "User: I'm getting an error when I try to import the 'pipeline' from transformers.\n",
    "Assistant: That might be due to an incorrect installation or version mismatch. Can you share the exact error message?\n",
    "User: The error says, 'ImportError: cannot import name 'pipeline' from 'transformers'.\n",
    "Assistant: It seems like there might be an issue with the installed version of the transformers library. \n",
    "Try updating it to the latest version using 'pip install --upgrade transformers'.\n",
    "User: I tried that, but now I'm getting an error related to TensorFlow when running the app.\n",
    "Assistant: You might need to ensure that TensorFlow is properly installed and compatible with the hardware. \n",
    "You can also try running the app with a smaller model if you're facing resource constraints.\n",
    "User: Thanks! That worked, but now the app is slow. Can you suggest a smaller model?\n",
    "Assistant: You can use 'facebook/bart-base' instead of 'bart-large-cnn' for summarization. It's smaller and faster.\n",
    "User: Great! That fixed it. Thanks for your help!\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarizer(text, max_length=200, min_length=20, do_sample=False)\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary:\")\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "MsgUser: Hi, I need help with deploying a model using Streamlit.MsgAssistant: Sure! What specific issues are you facing? _______________________________________________==========================================================User: I'm getting an error when I try to import the 'pipeline' from transformers. I'm not sure what the problem is. _______________________________________________________============Assistant: That might be due to an incorrect installation or version mismatch. Can you share the exact error message?___________________________________________=============================================================User: The error says, 'ImportError: cannot import name 'pilgrim' from 'transformers'. _______________________________________________________________==========================Assistant: It seems like there might be an\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "\n",
    "# Define the chat conversation\n",
    "chat = \"\"\"\n",
    "User: Hi, I need help with deploying a model using Streamlit.\n",
    "Assistant: Sure! What specific issues are you facing?\n",
    "User: I'm getting an error when I try to import the 'pipeline' from transformers.\n",
    "Assistant: That might be due to an incorrect installation or version mismatch. Can you share the exact error message?\n",
    "User: The error says, 'ImportError: cannot import name 'pipeline' from 'transformers'.\n",
    "Assistant: It seems like there might be an issue with the installed version of the transformers library. \n",
    "Try updating it to the latest version using 'pip install --upgrade transformers'.\n",
    "User: I tried that, but now I'm getting an error related to TensorFlow when running the app.\n",
    "Assistant: You might need to ensure that TensorFlow is properly installed and compatible with the hardware. \n",
    "You can also try running the app with a smaller model if you're facing resource constraints.\n",
    "User: Thanks! That worked, but now the app is slow. Can you suggest a smaller model?\n",
    "Assistant: You can use 'facebook/bart-base' instead of 'bart-large-cnn' for summarization. It's smaller and faster.\n",
    "User: Great! That fixed it. Thanks for your help!\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize and encode the chat\n",
    "inputs = tokenizer(chat, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashish.choudhary\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashish.choudhary\\.cache\\huggingface\\hub\\models--facebook--bart-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "ï¿½User: Hi, I need help with deploying a model using Streamlit.ï¿½Assistant: Sure! What specific issues are you facing? petertoddUser: I'm getting an error when I try to import the 'pipeline' from transformers. Can you share the exact error message? Â  Â  Â  Â  Â  Â  Â  Â User: The error says, 'ImportError: cannot import pipe from 'transformers' to'streamlit''. I'm trying to import pipeline from 'Streamlit' but I can't get it to work because I'm not able to get the name of the pipeline to work. Â  Â  Â  Â  Â  Â  Â  Â Assistant: It seems like there might be an issue with the installed version of the transformers library.  Â  Â  Â  Â  Â  Â  Â  Â Try updating it to the latest version using 'apt-get update --upgrade transformers'.ÝÝÌÝÌÌÌÌï¿½ï¿½ï¿½Ìï¿½ï¿½ï¿½Ìà¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "\n",
    "# Define the chat conversation\n",
    "chat = \"\"\"\n",
    "User: Hi, I need help with deploying a model using Streamlit.\n",
    "Assistant: Sure! What specific issues are you facing?\n",
    "User: I'm getting an error when I try to import the 'pipeline' from transformers.\n",
    "Assistant: That might be due to an incorrect installation or version mismatch. Can you share the exact error message?\n",
    "User: The error says, 'ImportError: cannot import name 'pipeline' from 'transformers'.\n",
    "Assistant: It seems like there might be an issue with the installed version of the transformers library. \n",
    "Try updating it to the latest version using 'pip install --upgrade transformers'.\n",
    "User: I tried that, but now I'm getting an error related to TensorFlow when running the app.\n",
    "Assistant: You might need to ensure that TensorFlow is properly installed and compatible with the hardware. \n",
    "You can also try running the app with a smaller model if you're facing resource constraints.\n",
    "User: Thanks! That worked, but now the app is slow. Can you suggest a smaller model?\n",
    "Assistant: You can use 'facebook/bart-base' instead of 'bart-large-cnn' for summarization. It's smaller and faster.\n",
    "User: Great! That fixed it. Thanks for your help!\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize and encode the chat\n",
    "inputs = tokenizer(chat, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    max_length=200,\n",
    "    min_length=50,\n",
    "    length_penalty=2.0,\n",
    "    num_beams=6,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
